# 理论



输入通道，有一个（32,32,3）的输入图像，卷积核为（3,5,5），3 为输入通道

如果有6个卷积核，那么输出就是（28,28,6）

那么矩阵就是（3,5,5,6）



核、卷积：

池化（最大值池化，均值池化） ：快速减少出入大小，保持原有土城

卷积神经网络=卷积层（参数学习 ）+池化层（无需学习）



## AlexNet

## VGGNet

## GooleNet

## ResNet:残差网络,避免梯度消失

- 直接和输出连接，规避梯度消失问题



## DenseNet



# 数据增强

## 图像缩放

```python
tf.image.resize_images(im,[100,200])
#args:
im:image,shape=[300,300,3]
[100,200]:缩放大小
method:tf.image.ResizeMethod.BILINEAR    
```

## 随机截取

```python
#第一种
tf.random_crop(im,shape)
	#args:
	im:输入图片
	shape:[100,100,3],随机截取位置
#第二种,中间
tf.image.central_crop(im,1./3)
```

## 随机翻转

```python
tf.image.random_flip_left_right(im)
tf.image.random_flip_up_down(im)
```

## 随机旋转

```python
tf.contrib.image.rotate(im,angle)
```

亮度/对比度/颜色调整

```python
#亮度
tf.image.randomw_brightness(……)
#色度
tf.image.random_contrasts(……)
#灰度
tf.image.random_hue(……)
```



# 学习率衰减

```python
def lr_step(step):
    lr=tf.cond(tf.less(step,12000),lambda:0.1,lambda:0.01)
    return lr
```



# Dropout

```python
tf.nn.dropout(x,keep_prob)
```

# 正则化

- 需要使用Slim



# Tensorflow

## 卷积：tf.nn.conv2d

```python
tf.nn.conv2d(
	input：数据集，4维tensor(数据集数量n_x,h,w,channels)
	filter:卷积核（h,w,in,out)
	strides:步长(1,h,w,1)
	padding:SAME,VALID
)
```



最大池化：tf.nn.max_pool

```
tf.nn.max_pool(
	value:数据集，4维tensor(数据集数量n_x,h,w,channels)
	ksize:池化核（1,h,w,1)
	strides:步长(1,h,w,1)
	padding:SAME,VALID
)
```











# 吴恩达学习

## 边沿检测

**Sobel Filter**

**Schar Filter**



## padding

卷积大小:(n+2p-f)/s+1

​	n:

​	p:padding

​		Vaild:不使用

​		Same:p=(f-1)/2    #因此建议使用奇数的过滤器

​	f:filter

​	s:stride

## Conv:卷积层



## Pool:池化层

**重要:**最大池化的理解X:看做为某些特征的集合,数字大意味着提取了某些特定特征,数字最大可能意味着:边缘/眼睛/CAP特征,数值越大,代表大可能性.

作用:

1/提取最大特征值(如上)

2/保持与其他层的n*n一致

3/缩小元素量



## 为什么用使用卷积

参数共享/稀疏连接



## ResNet:残缺模块,

把之前的激活函数a，放到目前激活函数中g(w[l]*z[l]+a[l-1])，解决梯度消失问题



## inception模块

选择用1x1，3x3，5*5，max_pool哪个比较好

1*1conv作用:

- 降低了计算成本
- 降低/增加通道

## 目标检测





## 卷积的滑动窗口实现



## YOLO



## 交并比IoU:>0.5

交并比=交集/并集



## 非极大值抑制



## anchor box

处理两个对象同时存在一个格子的问题